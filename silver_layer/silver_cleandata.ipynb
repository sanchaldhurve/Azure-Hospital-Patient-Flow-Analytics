{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02ba6db7-ac77-44db-8638-f66ae5ad024a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "The cluster was unhealthy or has been terminated. Please restart the cluster or attach this notebook to a different cluster.",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "#ADLS configuration \n",
    "spark.conf.set(\n",
    "  \"fs.azure.account.key.hospitalstorageac.dfs.core.windows.net\",\n",
    "  dbutils.secrets.get(scope = \"hospitalanalyticsvaultscope\", key = \"storage-connection\")\n",
    ")\n",
    "bronze_path = \"abfss://bronze@hospitalstorageac.dfs.core.windows.net/patient_flow\"\n",
    "silver_path = \"abfss://silver@hospitalstorageac.dfs.core.windows.net/patient_flow\"\n",
    "\n",
    "#read from bronze\n",
    "bronze_df = (\n",
    "    spark.readStream\n",
    "    .format(\"delta\")\n",
    "    .load(bronze_path)\n",
    ")\n",
    "\n",
    "#Defin Schema\n",
    "schema = StructType([\n",
    "    StructField(\"patient_id\", StringType()),\n",
    "    StructField(\"gender\", StringType()),\n",
    "    StructField(\"age\", IntegerType()),\n",
    "    StructField(\"department\", StringType()),\n",
    "    StructField(\"admission_time\", StringType()),\n",
    "    StructField(\"discharge_time\", StringType()),\n",
    "    StructField(\"bed_id\", IntegerType()),\n",
    "    StructField(\"hospital_id\", IntegerType())\n",
    "])\n",
    "\n",
    "#Parse it to dataframe\n",
    "parsed_df = bronze_df.withColumn(\"data\",from_json(col(\"raw_json\"),schema)).select(\"data.*\")\n",
    "\n",
    "#convert type to Timestamp\n",
    "clean_df = parsed_df.withColumn(\"admission_time\", to_timestamp(\"admission_time\"))\n",
    "clean_df = clean_df.withColumn(\"discharge_time\", to_timestamp(\"discharge_time\"))\n",
    "\n",
    "#invalid admission_times\n",
    "clean_df = clean_df.withColumn(\"admission_time\",\n",
    "                               when(\n",
    "                                   col(\"admission_time\").isNull() | (col(\"admission_time\") > current_timestamp()),\n",
    "                                   current_timestamp())\n",
    "                               .otherwise(col(\"admission_time\")))\n",
    "\n",
    "#Handle Invalid Age\n",
    "clean_df = clean_df.withColumn(\"age\",\n",
    "                               when(col(\"age\")>100,floor(rand()*90+1).cast(\"int\"))\n",
    "                               .otherwise(col(\"age\"))\n",
    "                               )\n",
    "\n",
    "#schema evolution\n",
    "expected_cols = [\"patient_id\", \"gender\", \"age\", \"department\", \"admission_time\", \"discharge_time\", \"bed_id\", \"hospital_id\"]\n",
    "\n",
    "for col_name in expected_cols:\n",
    "    if col_name not in clean_df.columns:\n",
    "        clean_df = clean_df.withColumn(col_name, lit(None))\n",
    "\n",
    "#Write to silver table\n",
    "(\n",
    "    clean_df.writeStream\n",
    "    .format(\"delta\")\n",
    "    .outputMode(\"append\")\n",
    "    .option(\"mergeSchema\",\"true\")\n",
    "    .option(\"checkpointLocation\", silver_path + \"_checkpoint\")\n",
    "    .start(silver_path)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2619e0be-b3a2-4de6-814b-661a234f926e",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1757388867261}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "The cluster was unhealthy or has been terminated. Please restart the cluster or attach this notebook to a different cluster.",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.read.format(\"delta\").load(silver_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e374444-da33-4519-92ba-1b498524b5c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_silver_cleandata",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}